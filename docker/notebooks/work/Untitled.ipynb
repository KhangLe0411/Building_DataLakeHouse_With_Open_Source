{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5286265b-12d2-4cd4-8ced-bd3201515627",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# spark = SparkSession.builder.appName(\"demo\").master(\"spark://spark-master:7077\").getOrCreate()\n",
    "spark = SparkSession.builder \\\n",
    "            .appName(\"demo\") \\\n",
    "            .master(\"spark://spark-master:7077\") \\\n",
    "            .config(\"spark.sql.catalog.spark_catalog\",\"org.apache.iceberg.spark.SparkSessionCatalog\") \\\n",
    "            .config(\"spark.sql.catalog.spark_catalog.type\",\"hive\") \\\n",
    "            .config(\"spark.sql.catalog.iceberg\",\"org.apache.iceberg.spark.SparkCatalog\") \\\n",
    "            .config(\"spark.sql.catalog.iceberg.type\",\"hive\") \\\n",
    "            .config(\"spark.sql.catalog.iceberg.uri\",\"thrift://hive-metastore:9083\") \\\n",
    "            .config('spark.sql.warehouse.dir', 's3a://lakehouse/') \\\n",
    "            .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2f1c412-388b-4a3d-aa29-5a0576e68190",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f464cd1f-a21f-4326-ba1a-8a5ebf06e91d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+-----------+-----------+-----+-----+-----+-----+-------+\n",
      "| ID|symbol|      value|tradingDate| open| high|  low|close| volume|\n",
      "+---+------+-----------+-----------+-----+-----+-----+-----+-------+\n",
      "|  1|   ACB|43975750000| 2013-01-02|16300|17400|16300|17300|2578600|\n",
      "|  2|   ACB|33790120000| 2013-01-03|17500|17800|16700|17000|1967200|\n",
      "|  3|   ACB|19893160000| 2013-01-04|16900|17200|16700|17200|1170100|\n",
      "|  4|   ACB|23335900000| 2013-01-07|17000|17500|17000|17200|1355700|\n",
      "|  5|   ACB|37493390000| 2013-01-08|17100|17500|16900|17300|2180000|\n",
      "|  6|   ACB|69459100000| 2013-01-09|17100|18200|17100|18100|3861400|\n",
      "|  7|   ACB|15857090000| 2013-01-10|18100|18300|17700|18300| 880700|\n",
      "|  8|   ACB|14849120000| 2013-01-11|19000|19000|18200|18200| 806200|\n",
      "|  9|   ACB|11046650000| 2013-01-14|18400|18400|17700|18000| 614300|\n",
      "| 10|   ACB|23515790000| 2013-01-15|18200|18300|17600|18200|1310500|\n",
      "+---+------+-----------+-----------+-----+-----+-----+-----+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.format(\"parquet\").load(\"s3a://lakehouse/bronze/trade/trades.parquet\")\n",
    "df.show(10)\n",
    "# type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b693c859-01d1-444e-89b0-8c8f31156e9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2013, 1, 2)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from datetime import datetime, timedelta\n",
    "from pyspark.sql.types import *\n",
    "# from pyspark.sql import functions as F\n",
    "# df = df \\\n",
    "#     .withColumnRenamed(\"open\", \"open_price\") \\\n",
    "#     .withColumnRenamed(\"high\", \"high_price\") \\\n",
    "#     .withColumnRenamed(\"low\", \"low_price\") \\\n",
    "#     .withColumnRenamed(\"close\", \"close_price\") \\\n",
    "#     .withColumnRenamed(\"TradingDate\", \"date\") \\\n",
    "#     .drop('ID') \\\n",
    "#     .dropDuplicates(['symbol', 'date'])\n",
    "# df.count()\n",
    "# filtered_df = df.filter((col(\"symbol\") == \"SSI\") & (col(\"tradingDate\") == \"2016-09-23\"))\n",
    "# filtered_df.show()\n",
    "# duplicate_rows = df.groupBy(['symbol', 'date']).count().where(col(\"count\") > 1)\n",
    "# duplicate_rows.show(30)\n",
    "start_date = datetime.strptime('2013-01-02', '%Y-%m-%d').date()\n",
    "end_date = datetime.strptime('2023-06-30', '%Y-%m-%d').date()\n",
    "\n",
    "# Tạo DataFrame với cột \"date\"\n",
    "# date_df \n",
    "# date_range = spark.sparkContext.parallelize([(start_date + timedelta(days=x)) for x in range((end_date - start_date).days + 1)])\n",
    "# date_df = date_range.map(lambda x: (x,)).toDF(['date'])\n",
    "\n",
    "# date_df = date_df.withColumn(\"dateKey\", year(col(\"date\"))*10000 + month(col(\"date\"))*100 + dayofmonth(col(\"date\"))) \\\n",
    "#     .withColumn(\"year\", year(col(\"date\"))) \\\n",
    "#     .withColumn(\"quarter\", quarter(col(\"date\"))) \\\n",
    "#     .withColumn(\"month\", month(col(\"date\"))) \\\n",
    "#     .withColumn(\"week\", weekofyear(col(\"date\"))) \\\n",
    "#     .withColumn(\"day\", dayofmonth(col(\"date\"))) \\\n",
    "#     .withColumn(\"day_of_year\", dayofyear(col(\"date\"))) \\\n",
    "#     .withColumn(\"day_name_of_week\", date_format(col(\"date\"), \"EEEE\")) \\\n",
    "#     .withColumn(\"month_name_of_week\", date_format(col(\"date\"), \"MMMM\")) \\\n",
    "#     .withColumnRenamed(\"date\", \"full_date\") \\\n",
    "#     .selectExpr(['dateKey', 'full_date', 'year', 'quarter', 'month', 'week', 'day', 'day_of_year', 'day_name_of_week', 'month_name_of_week'])\n",
    "\n",
    "# date_df.show(10)\n",
    "start_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a3c10ad5-7d7a-4c09-81ac-d3f6f851cbbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2013, 1, 2)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_age = df.select(min(\"tradingDate\")).first()[0]\n",
    "min_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d91cb5ca-33bd-4598-98d0-f1118e217438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|namespace|\n",
      "+---------+\n",
      "|  default|\n",
      "|   silver|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# spark.sql(f\"CREATE SCHEMA IF NOT EXISTS iceberg.db1\")\n",
    "# spark.sql(\"CREATE DATABASE IF NOT EXISTS hive_prod.db2 location 's3a://lakehouse/db2.db/';\")\n",
    "# spark.sql(\"CREATE TABLE IF NOT EXISTS iceberg.db1.stock3s (Symbol string, CompanyName string, Series string, Industry string, ISIN_Code string) USING iceberg\")\n",
    "# spark.sql(f\"CREATE TABLE IF NOT EXISTS hive_prod.silver.stocks (Symbol string, CompanyName string, Series string, Industry string, ISIN_Code string) USING iceberg\")\n",
    "# spark.sql(\"CREATE TABLE IF NOT EXISTS hive_prod.silver.stock2s (Symbol string, CompanyName string, Series string, Industry string, ISIN_Code string) USING iceberg\")\n",
    "# spark.sql(f\"CREATE TABLE IF NOT EXISTS hive_prod.silver.stocksss (Symbol varchar(100), CompanyName varchar(100), Series varchar(100), Industry varchar(100), ISIN_Code varchar(100)) USING iceberg\")\n",
    "# spark.sql(\"SHOW TABLES FROM iceberg.db1\").show()\n",
    "spark.sql(\"SHOW DATABASES FROM iceberg\").show()\n",
    "# spark.sql(\"SHOW catalogs\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81a15033-6f12-46a9-b42c-5a3dd615ed62",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.format(\"iceberg\").mode(\"overwrite\").saveAsTable(\"iceberg.db1.stock\")\n",
    "# df.createOrReplaceTempView(\"stock2s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f88de66a-a140-4769-b615-1d80580d20f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.writeTo(\"iceberg.db1.stock3s\").append()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67c1bc9-c765-4252-92eb-c23979895e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc7a63ac-d576-48bd-b379-d955dea8b569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+----------+----------+---------+-----------+-------+\n",
      "| dateKey|companyKey|open_price|high_price|low_price|close_price| Volume|\n",
      "+--------+----------+----------+----------+---------+-----------+-------+\n",
      "|20130228|       CTG|     21100|     21200|    20000|      20000|2846940|\n",
      "|20130117|       GAS|     43700|     43800|    42000|      42000| 505310|\n",
      "|20180208|       HDB|     43850|     45850|    43500|      44900|4667920|\n",
      "|20170123|       NVL|     58200|     58400|    57800|      57800|1087390|\n",
      "|20140109|       ACB|     15700|     15900|    15700|      15900|  71800|\n",
      "|20160114|       ACB|     19200|     19200|    18900|      19000| 315858|\n",
      "|20160301|       ACB|     19700|     19800|    19600|      19600| 140511|\n",
      "|20161031|       ACB|     19300|     19400|    19000|      19000| 200973|\n",
      "|20200526|       ACB|     22500|     23500|    22500|      23300|5262900|\n",
      "|20200909|       ACB|     20600|     20900|    20300|      20900|5019800|\n",
      "+--------+----------+----------+----------+---------+-----------+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cleaned_trades = spark.read.format(\"iceberg\").load(\"iceberg.silver.cleaned_trades\")\n",
    "dim_date = spark.read.format(\"iceberg\").load(\"iceberg.silver.dim_date\")\n",
    "dim_company = spark.read.format(\"iceberg\").load(\"iceberg.silver.dim_company\")\n",
    "fact_table = (\n",
    "        cleaned_trades\n",
    "        .join(dim_company, cleaned_trades['symbol'] == dim_company['companyKey'], 'inner')\n",
    "        .join(dim_date, cleaned_trades['tradingDate'] == dim_date['full_date'], 'inner')\n",
    "        .select('dateKey', 'companyKey', 'open_price', 'high_price', 'low_price', 'close_price', 'Volume')\n",
    "    )\n",
    "fact_table.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f8fd4d1d-c8cf-4621-82cd-dd5d1e106e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+----+-------+-----+----+---+-----------+----------------+------------------+\n",
      "| dateKey|          full_date|year|quarter|month|week|day|day_of_year|day_name_of_week|month_name_of_week|\n",
      "+--------+-------------------+----+-------+-----+----+---+-----------+----------------+------------------+\n",
      "|20130102|2013-01-02 00:00:00|2013|      1|    1|   1|  2|          2|       Wednesday|           January|\n",
      "|20130103|2013-01-03 00:00:00|2013|      1|    1|   1|  3|          3|        Thursday|           January|\n",
      "|20130104|2013-01-04 00:00:00|2013|      1|    1|   1|  4|          4|          Friday|           January|\n",
      "|20130105|2013-01-05 00:00:00|2013|      1|    1|   1|  5|          5|        Saturday|           January|\n",
      "|20130106|2013-01-06 00:00:00|2013|      1|    1|   1|  6|          6|          Sunday|           January|\n",
      "|20130107|2013-01-07 00:00:00|2013|      1|    1|   2|  7|          7|          Monday|           January|\n",
      "|20130108|2013-01-08 00:00:00|2013|      1|    1|   2|  8|          8|         Tuesday|           January|\n",
      "|20130109|2013-01-09 00:00:00|2013|      1|    1|   2|  9|          9|       Wednesday|           January|\n",
      "|20130110|2013-01-10 00:00:00|2013|      1|    1|   2| 10|         10|        Thursday|           January|\n",
      "|20130111|2013-01-11 00:00:00|2013|      1|    1|   2| 11|         11|          Friday|           January|\n",
      "|20130112|2013-01-12 00:00:00|2013|      1|    1|   2| 12|         12|        Saturday|           January|\n",
      "|20130113|2013-01-13 00:00:00|2013|      1|    1|   2| 13|         13|          Sunday|           January|\n",
      "|20130114|2013-01-14 00:00:00|2013|      1|    1|   3| 14|         14|          Monday|           January|\n",
      "|20130115|2013-01-15 00:00:00|2013|      1|    1|   3| 15|         15|         Tuesday|           January|\n",
      "|20130116|2013-01-16 00:00:00|2013|      1|    1|   3| 16|         16|       Wednesday|           January|\n",
      "|20130117|2013-01-17 00:00:00|2013|      1|    1|   3| 17|         17|        Thursday|           January|\n",
      "|20130118|2013-01-18 00:00:00|2013|      1|    1|   3| 18|         18|          Friday|           January|\n",
      "|20130119|2013-01-19 00:00:00|2013|      1|    1|   3| 19|         19|        Saturday|           January|\n",
      "|20130120|2013-01-20 00:00:00|2013|      1|    1|   3| 20|         20|          Sunday|           January|\n",
      "|20130121|2013-01-21 00:00:00|2013|      1|    1|   4| 21|         21|          Monday|           January|\n",
      "|20130122|2013-01-22 00:00:00|2013|      1|    1|   4| 22|         22|         Tuesday|           January|\n",
      "|20130123|2013-01-23 00:00:00|2013|      1|    1|   4| 23|         23|       Wednesday|           January|\n",
      "|20130124|2013-01-24 00:00:00|2013|      1|    1|   4| 24|         24|        Thursday|           January|\n",
      "|20130125|2013-01-25 00:00:00|2013|      1|    1|   4| 25|         25|          Friday|           January|\n",
      "|20130126|2013-01-26 00:00:00|2013|      1|    1|   4| 26|         26|        Saturday|           January|\n",
      "|20130127|2013-01-27 00:00:00|2013|      1|    1|   4| 27|         27|          Sunday|           January|\n",
      "|20130128|2013-01-28 00:00:00|2013|      1|    1|   5| 28|         28|          Monday|           January|\n",
      "|20130129|2013-01-29 00:00:00|2013|      1|    1|   5| 29|         29|         Tuesday|           January|\n",
      "|20130130|2013-01-30 00:00:00|2013|      1|    1|   5| 30|         30|       Wednesday|           January|\n",
      "|20130131|2013-01-31 00:00:00|2013|      1|    1|   5| 31|         31|        Thursday|           January|\n",
      "|20130201|2013-02-01 00:00:00|2013|      1|    2|   5|  1|         32|          Friday|          February|\n",
      "|20130202|2013-02-02 00:00:00|2013|      1|    2|   5|  2|         33|        Saturday|          February|\n",
      "|20130203|2013-02-03 00:00:00|2013|      1|    2|   5|  3|         34|          Sunday|          February|\n",
      "|20130204|2013-02-04 00:00:00|2013|      1|    2|   6|  4|         35|          Monday|          February|\n",
      "|20130205|2013-02-05 00:00:00|2013|      1|    2|   6|  5|         36|         Tuesday|          February|\n",
      "|20130206|2013-02-06 00:00:00|2013|      1|    2|   6|  6|         37|       Wednesday|          February|\n",
      "|20130207|2013-02-07 00:00:00|2013|      1|    2|   6|  7|         38|        Thursday|          February|\n",
      "|20130208|2013-02-08 00:00:00|2013|      1|    2|   6|  8|         39|          Friday|          February|\n",
      "|20130209|2013-02-09 00:00:00|2013|      1|    2|   6|  9|         40|        Saturday|          February|\n",
      "|20130210|2013-02-10 00:00:00|2013|      1|    2|   6| 10|         41|          Sunday|          February|\n",
      "+--------+-------------------+----+-------+-----+----+---+-----------+----------------+------------------+\n",
      "only showing top 40 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dim_date.show(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f3540101-611f-4538-a930-8f8008f8a0b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+-------------------+----+---+----------+-----------+-------+----------------+--------------+\n",
      "|companyKey|      organShortName|          full_date|year|day|open_price|close_price| Volume|day_price_change|percent_change|\n",
      "+----------+--------------------+-------------------+----+---+----------+-----------+-------+----------------+--------------+\n",
      "|       CTG|          VietinBank|2013-02-28 00:00:00|2013| 28|     21100|      20000|2846940|           -1100|         -5.21|\n",
      "|       GAS|              PV Gas|2013-01-17 00:00:00|2013| 17|     43700|      42000| 505310|           -1700|         -3.89|\n",
      "|       HDB|              HDBank|2018-02-08 00:00:00|2018|  8|     43850|      44900|4667920|            1050|          2.39|\n",
      "|       NVL|Đầu tư Địa ốc No ...|2017-01-23 00:00:00|2017| 23|     58200|      57800|1087390|            -400|         -0.69|\n",
      "|       ACB|                 ACB|2014-01-09 00:00:00|2014|  9|     15700|      15900|  71800|             200|          1.27|\n",
      "|       ACB|                 ACB|2016-01-14 00:00:00|2016| 14|     19200|      19000| 315858|            -200|         -1.04|\n",
      "|       ACB|                 ACB|2016-03-01 00:00:00|2016|  1|     19700|      19600| 140511|            -100|         -0.51|\n",
      "|       ACB|                 ACB|2016-10-31 00:00:00|2016| 31|     19300|      19000| 200973|            -300|         -1.55|\n",
      "|       ACB|                 ACB|2020-05-26 00:00:00|2020| 26|     22500|      23300|5262900|             800|          3.56|\n",
      "|       ACB|                 ACB|2020-09-09 00:00:00|2020|  9|     20600|      20900|5019800|             300|          1.46|\n",
      "+----------+--------------------+-------------------+----+---+----------+-----------+-------+----------------+--------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "tdf = (\n",
    "    fact_table\n",
    "    .withColumn(\"day_price_change\", col('close_price') - col('open_price'))\n",
    "    .withColumn(\"percent_change\", bround((col('day_price_change') / col('open_price')) * 100, 2))\n",
    "    .join(dim_date, 'dateKey', 'inner')\n",
    "    .join(dim_company, 'companyKey', 'inner')\n",
    "    .select('companyKey', 'organShortName', 'full_date', 'year', 'day', 'open_price', 'close_price', 'Volume', 'day_price_change', 'percent_change')\n",
    ")\n",
    "tdf.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "703d06d0-8f0b-4357-9481-ec057db5274b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+-------------------+------+------+------------+--------+\n",
      "|companyKey|      organShortName|          full_date|  open| close|price_change|%_change|\n",
      "+----------+--------------------+-------------------+------+------+------------+--------+\n",
      "|       PDR|        BĐS Phát Đạt|2023-06-30 00:00:00| 16450| 16800|         350|    2.13|\n",
      "|       HPG|            Hòa Phát|2023-06-30 00:00:00| 25700| 26150|         450|    1.75|\n",
      "|       MWG|    Thế giới di động|2023-06-30 00:00:00| 42700| 43300|         600|    1.41|\n",
      "|       GVR|Tập đoàn CN Cao s...|2023-06-30 00:00:00| 19150| 19400|         250|    1.31|\n",
      "|       SSI|     Chứng khoán SSI|2023-06-30 00:00:00| 25500| 25800|         300|    1.18|\n",
      "|       STB|           Sacombank|2023-06-30 00:00:00| 29550| 29800|         250|    0.85|\n",
      "|       ACB|                 ACB|2023-06-30 00:00:00| 21900| 22050|         150|    0.68|\n",
      "|       HDB|              HDBank|2023-06-30 00:00:00| 18500| 18600|         100|    0.54|\n",
      "|       VJC|         Vietjet Air|2023-06-30 00:00:00| 93800| 94300|         500|    0.53|\n",
      "|       VHM|            Vinhomes|2023-06-30 00:00:00| 54800| 55000|         200|    0.36|\n",
      "|       VNM|            VINAMILK|2023-06-29 00:00:00| 70600| 71900|        1300|    1.84|\n",
      "|       VCB|         Vietcombank|2023-06-29 00:00:00|101800|101900|         100|     0.1|\n",
      "|       MBB|              MBBank|2023-06-28 00:00:00| 20200| 20700|         500|    2.48|\n",
      "|       BID|                BIDV|2023-06-28 00:00:00| 44300| 45350|        1050|    2.37|\n",
      "|       HPG|            Hòa Phát|2023-06-28 00:00:00| 26000| 26600|         600|    2.31|\n",
      "|       CTG|          VietinBank|2023-06-28 00:00:00| 29400| 30000|         600|    2.04|\n",
      "|       NVL|Đầu tư Địa ốc No ...|2023-06-28 00:00:00| 15350| 15600|         250|    1.63|\n",
      "|       VCB|         Vietcombank|2023-06-28 00:00:00|100000|101100|        1100|     1.1|\n",
      "|       TCB|         Techcombank|2023-06-28 00:00:00| 32950| 33300|         350|    1.06|\n",
      "|       POW|Điện lực Dầu khí ...|2023-06-28 00:00:00| 13700| 13800|         100|    0.73|\n",
      "+----------+--------------------+-------------------+------+------+------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "z = tdf \\\n",
    "    .filter(col('percent_change') > 0) \\\n",
    "    .groupBy('companyKey', 'organShortName', 'full_date') \\\n",
    "    .agg(\n",
    "        bround(sum('open_price'), 2).alias('open'),\n",
    "        bround(sum('close_price'), 2).alias('close'),\n",
    "        bround(sum('day_price_change'), 2).alias('price_change'),\n",
    "        bround(sum('percent_change'), 2).alias('%_change'),\n",
    "    ) \\\n",
    "    .orderBy(desc(max('full_date')), desc(max('percent_change')))\n",
    "z.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a765ce65-273f-4046-a477-d011eb1d4106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+-------------------+------+------+------------+--------+\n",
      "|companyKey|      organShortName|          full_date|  open| close|price_change|%_change|\n",
      "+----------+--------------------+-------------------+------+------+------------+--------+\n",
      "|       BID|                BIDV|2023-06-30 00:00:00| 44500| 43350|       -1150|   -2.58|\n",
      "|       GAS|              PV Gas|2023-06-30 00:00:00| 94600| 93000|       -1600|   -1.69|\n",
      "|       VIC|            VinGroup|2023-06-30 00:00:00| 51800| 51000|        -800|   -1.54|\n",
      "|       VNM|            VINAMILK|2023-06-30 00:00:00| 71900| 71000|        -900|   -1.25|\n",
      "|       POW|Điện lực Dầu khí ...|2023-06-30 00:00:00| 13550| 13400|        -150|   -1.11|\n",
      "|       VRE|       Vincom Retail|2023-06-30 00:00:00| 27100| 26800|        -300|   -1.11|\n",
      "|       VCB|         Vietcombank|2023-06-30 00:00:00|101100|100000|       -1100|   -1.09|\n",
      "|       NVL|Đầu tư Địa ốc No ...|2023-06-30 00:00:00| 15000| 14850|        -150|    -1.0|\n",
      "|       TCB|         Techcombank|2023-06-30 00:00:00| 32650| 32350|        -300|   -0.92|\n",
      "|       BVH|   Tập đoàn Bảo Việt|2023-06-30 00:00:00| 44400| 44100|        -300|   -0.68|\n",
      "|       CTG|          VietinBank|2023-06-30 00:00:00| 29700| 29500|        -200|   -0.67|\n",
      "|       PLX|          Petrolimex|2023-06-30 00:00:00| 37600| 37350|        -250|   -0.66|\n",
      "|       FPT|            FPT Corp|2023-06-30 00:00:00| 86500| 86000|        -500|   -0.58|\n",
      "|       TPB|              TPBank|2023-06-30 00:00:00| 18100| 18000|        -100|   -0.55|\n",
      "|       SAB|              SABECO|2023-06-30 00:00:00|154400|153600|        -800|   -0.52|\n",
      "|       VIB|             VIBBank|2023-06-30 00:00:00| 19750| 19650|        -100|   -0.51|\n",
      "|       MBB|              MBBank|2023-06-30 00:00:00| 20300| 20200|        -100|   -0.49|\n",
      "|       MSN|      Tập đoàn Masan|2023-06-30 00:00:00| 75400| 75200|        -200|   -0.27|\n",
      "|       VPB|              VPBank|2023-06-30 00:00:00| 19900| 19850|         -50|   -0.25|\n",
      "|       BCM|         Becamex IDC|2023-06-30 00:00:00| 79200| 79200|           0|     0.0|\n",
      "|       NVL|Đầu tư Địa ốc No ...|2023-06-29 00:00:00| 15800| 15000|        -800|   -5.06|\n",
      "|       SSI|     Chứng khoán SSI|2023-06-29 00:00:00| 26650| 25450|       -1200|    -4.5|\n",
      "|       PDR|        BĐS Phát Đạt|2023-06-29 00:00:00| 17150| 16500|        -650|   -3.79|\n",
      "|       HPG|            Hòa Phát|2023-06-29 00:00:00| 26650| 25800|        -850|   -3.19|\n",
      "|       TPB|              TPBank|2023-06-29 00:00:00| 18500| 18100|        -400|   -2.16|\n",
      "|       HDB|              HDBank|2023-06-29 00:00:00| 18750| 18350|        -400|   -2.13|\n",
      "|       BVH|   Tập đoàn Bảo Việt|2023-06-29 00:00:00| 45250| 44300|        -950|    -2.1|\n",
      "|       BID|                BIDV|2023-06-29 00:00:00| 45400| 44500|        -900|   -1.98|\n",
      "|       VPB|              VPBank|2023-06-29 00:00:00| 20300| 19900|        -400|   -1.97|\n",
      "|       TCB|         Techcombank|2023-06-29 00:00:00| 33300| 32650|        -650|   -1.95|\n",
      "|       MBB|              MBBank|2023-06-29 00:00:00| 20700| 20300|        -400|   -1.93|\n",
      "|       MWG|    Thế giới di động|2023-06-29 00:00:00| 43500| 42700|        -800|   -1.84|\n",
      "|       PLX|          Petrolimex|2023-06-29 00:00:00| 38200| 37500|        -700|   -1.83|\n",
      "|       MSN|      Tập đoàn Masan|2023-06-29 00:00:00| 76800| 75400|       -1400|   -1.82|\n",
      "|       ACB|                 ACB|2023-06-29 00:00:00| 22300| 21900|        -400|   -1.79|\n",
      "|       STB|           Sacombank|2023-06-29 00:00:00| 29950| 29550|        -400|   -1.34|\n",
      "|       POW|Điện lực Dầu khí ...|2023-06-29 00:00:00| 13700| 13550|        -150|   -1.09|\n",
      "|       GAS|              PV Gas|2023-06-29 00:00:00| 95500| 94600|        -900|   -0.94|\n",
      "|       BCM|         Becamex IDC|2023-06-29 00:00:00| 79900| 79200|        -700|   -0.88|\n",
      "|       VJC|         Vietjet Air|2023-06-29 00:00:00| 94900| 94100|        -800|   -0.84|\n",
      "|       SAB|              SABECO|2023-06-29 00:00:00|155200|154000|       -1200|   -0.77|\n",
      "|       VIC|            VinGroup|2023-06-29 00:00:00| 52200| 51800|        -400|   -0.77|\n",
      "|       VIB|             VIBBank|2023-06-29 00:00:00| 19900| 19750|        -150|   -0.75|\n",
      "|       VRE|       Vincom Retail|2023-06-29 00:00:00| 27200| 27000|        -200|   -0.74|\n",
      "|       VHM|            Vinhomes|2023-06-29 00:00:00| 55400| 55000|        -400|   -0.72|\n",
      "|       FPT|            FPT Corp|2023-06-29 00:00:00| 87000| 86500|        -500|   -0.57|\n",
      "|       CTG|          VietinBank|2023-06-29 00:00:00| 30000| 29900|        -100|   -0.33|\n",
      "|       GVR|Tập đoàn CN Cao s...|2023-06-29 00:00:00| 19100| 19050|         -50|   -0.26|\n",
      "|       BCM|         Becamex IDC|2023-06-28 00:00:00| 81500| 80000|       -1500|   -1.84|\n",
      "|       GAS|              PV Gas|2023-06-28 00:00:00| 96900| 95400|       -1500|   -1.55|\n",
      "+----------+--------------------+-------------------+------+------+------------+--------+\n",
      "only showing top 50 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = tdf \\\n",
    "    .filter(col('percent_change') <= 0) \\\n",
    "    .groupBy('companyKey', 'organShortName', 'full_date') \\\n",
    "    .agg(\n",
    "        bround(sum('open_price'), 2).alias('open'),\n",
    "        bround(sum('close_price'), 2).alias('close'),\n",
    "        bround(sum('day_price_change'), 2).alias('price_change'),\n",
    "        bround(sum('percent_change'), 2).alias('%_change'),\n",
    "    ) \\\n",
    "    .orderBy(desc(max('full_date')), asc(min('percent_change')))\n",
    "x.show(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c258901c-bdc6-482c-9cc3-49cfa66ac9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.write.format(\"iceberg\").mode(\"overwrite\").saveAsTable(\"iceberg.data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76b72b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ecb705-47cf-42c3-b221-4c75eefbbede",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS hive_prod.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978d1ae0-e0aa-4177-ac1f-185d058d852d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"CREATE TABLE IF NOT EXISTS hive_prod.db.stock (Symbol string, CompanyName string, Series string, Industry string, ISIN_Code string) USING iceberg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a162888b-34bf-42e5-bc0e-c7dc98ca4eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# player.writeTo(\"hive_prod.db.stock\").append()\n",
    "player.writeTo(\"hive_prod.db.sal\").using(\"iceberg\").create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d65584-c16c-4a66-9fc6-12227d9b1cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "icebergdf = spark.read.format(\"iceberg\").load(\"hive_prod.db.sal\")\n",
    "icebergdf.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64578b6f-76be-4281-be19-b2f0c600af6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "player = spark.read \\\n",
    "    .format(\"parquet\") \\\n",
    "    .load(\"s3a://lakehouse/bronze/stock/stocks.parquet\")\n",
    "\n",
    "player.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708065ba-6d06-4d07-b791-c28c44335517",
   "metadata": {},
   "outputs": [],
   "source": [
    "player.createOrReplaceTempView(\"player\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915da182-d240-4bd9-8eee-41e4b7ee7583",
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlContext = SparkSession(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc2b927-f900-4ad0-aea9-ba488210633a",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = sqlContext.sql(\"SELECT * FROM player\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14a83ea-67a7-45ae-9416-40c4f1e706a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "t.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8f660c-64bf-4ad2-bc90-a286c7fc0c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "t.write.format(\"iceberg\").save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecafbb9-613a-4818-9365-a750d64372df",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = spark.read \\\n",
    "    .format(\"csv\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .load(\"s3a://test/ADANIPORTS.csv\")\n",
    "\n",
    "t.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf2b8c2-f4fa-4ae6-8c2c-2d06b3e919c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b1ff07-7f87-404f-922a-381bc7ba5995",
   "metadata": {},
   "outputs": [],
   "source": [
    "file:///usr/local/spark-3.3.2-bin-hadoop3/jars/hadoop-aws-3.3.2.jar,file:///usr/local/spark-3.3.2-bin-hadoop3/jars/hadoop-common-3.3.2.jar,file:///usr/local/spark-3.3.2-bin-hadoop3/jars/aws-java-sdk-1.12.367.jar,file:///usr/local/spark-3.3.2-bin-hadoop3/jars/s3-2.18.41.jar,file:///usr/local/spark-3.3.2-bin-hadoop3/jars/aws-java-sdk-bundle-1.11.1026.jar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e5b848-a61b-41bc-bf34-9e223b3a61c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b8ebef14-48dc-44e7-afde-3a582aa79119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('ADANIPORTS', 'Adani Ports and Special Economic Zone Ltd.', 'EQ', 'SERVICES', 'INE742F01042'), ('ASIANPAINT', 'Asian Paints Ltd.', 'EQ', 'CONSUMER GOODS', 'INE021A01026'), ('AXISBANK', 'Axis Bank Ltd.', 'EQ', 'FINANCIAL SERVICES', 'INE238A01034'), ('BPCL', 'Bharat Petroleum Corporation Ltd.', 'EQ', 'ENERGY', 'INE029A01011'), ('BRITANNIA', 'Britannia Industries Ltd.', 'EQ', 'CONSUMER GOODS', 'INE216A01030'), ('CIPLA', 'Cipla Ltd.', 'EQ', 'PHARMA', 'INE059A01026'), ('COALINDIA', 'Coal India Ltd.', 'EQ', 'METALS', 'INE522F01014'), ('DRREDDY', \"Dr. Reddy's Laboratories Ltd.\", 'EQ', 'PHARMA', 'INE089A01023'), ('EICHERMOT', 'Eicher Motors Ltd.', 'EQ', 'AUTOMOBILE', 'INE066A01013'), ('GAIL', 'GAIL (India) Ltd.', 'EQ', 'ENERGY', 'INE129A01019'), ('GRASIM', 'Grasim Industries Ltd.', 'EQ', 'CEMENT & CEMENT PRODUCTS', 'INE047A01021'), ('BAJAJ-AUTO', 'Bajaj Auto Ltd.', 'EQ', 'AUTOMOBILE', 'INE917I01010'), ('BAJAJFINSV', 'Bajaj Finserv Ltd.', 'EQ', 'FINANCIAL SERVICES', 'INE918I01018'), ('BAJFINANCE', 'Bajaj Finance Ltd.', 'EQ', 'FINANCIAL SERVICES', 'INE296A01024'), ('BHARTIARTL', 'Bharti Airtel Ltd.', 'EQ', 'TELECOM', 'INE397D01024'), ('HCLTECH', 'HCL Technologies Ltd.', 'EQ', 'IT', 'INE860A01027'), ('HDFC', 'Housing Development Finance Corporation Ltd.', 'EQ', 'FINANCIAL SERVICES', 'INE001A01036'), ('HDFCBANK', 'HDFC Bank Ltd.', 'EQ', 'FINANCIAL SERVICES', 'INE040A01034'), ('HEROMOTOCO', 'Hero MotoCorp Ltd.', 'EQ', 'AUTOMOBILE', 'INE158A01026'), ('HINDALCO', 'Hindalco Industries Ltd.', 'EQ', 'METALS', 'INE038A01020'), ('HINDUNILVR', 'Hindustan Unilever Ltd.', 'EQ', 'CONSUMER GOODS', 'INE030A01027'), ('ICICIBANK', 'ICICI Bank Ltd.', 'EQ', 'FINANCIAL SERVICES', 'INE090A01021'), ('INDUSINDBK', 'IndusInd Bank Ltd.', 'EQ', 'FINANCIAL SERVICES', 'INE095A01012'), ('INFY', 'Infosys Ltd.', 'EQ', 'IT', 'INE009A01021'), ('IOC', 'Indian Oil Corporation Ltd.', 'EQ', 'ENERGY', 'INE242A01010'), ('ITC', 'ITC Ltd.', 'EQ', 'CONSUMER GOODS', 'INE154A01025'), ('JSWSTEEL', 'JSW Steel Ltd.', 'EQ', 'METALS', 'INE019A01038'), ('KOTAKBANK', 'Kotak Mahindra Bank Ltd.', 'EQ', 'FINANCIAL SERVICES', 'INE237A01028'), ('LT', 'Larsen & Toubro Ltd.', 'EQ', 'CONSTRUCTION', 'INE018A01030'), ('M&M', 'Mahindra & Mahindra Ltd.', 'EQ', 'AUTOMOBILE', 'INE101A01026'), ('MARUTI', 'Maruti Suzuki India Ltd.', 'EQ', 'AUTOMOBILE', 'INE585B01010'), ('NESTLEIND', 'Nestle India Ltd.', 'EQ', 'CONSUMER GOODS', 'INE239A01016'), ('NTPC', 'NTPC Ltd.', 'EQ', 'ENERGY', 'INE733E01010'), ('ONGC', 'Oil & Natural Gas Corporation Ltd.', 'EQ', 'ENERGY', 'INE213A01029'), ('POWERGRID', 'Power Grid Corporation of India Ltd.', 'EQ', 'ENERGY', 'INE752E01010'), ('RELIANCE', 'Reliance Industries Ltd.', 'EQ', 'ENERGY', 'INE002A01018'), ('SBIN', 'State Bank of India', 'EQ', 'FINANCIAL SERVICES', 'INE062A01020'), ('SHREECEM', 'Shree Cement Ltd.', 'EQ', 'CEMENT & CEMENT PRODUCTS', 'INE070A01015'), ('SUNPHARMA', 'Sun Pharmaceutical Industries Ltd.', 'EQ', 'PHARMA', 'INE044A01036'), ('TATAMOTORS', 'Tata Motors Ltd.', 'EQ', 'AUTOMOBILE', 'INE155A01022'), ('TATASTEEL', 'Tata Steel Ltd.', 'EQ', 'METALS', 'INE081A01012'), ('TCS', 'Tata Consultancy Services Ltd.', 'EQ', 'IT', 'INE467B01029'), ('TECHM', 'Tech Mahindra Ltd.', 'EQ', 'IT', 'INE669C01036'), ('TITAN', 'Titan Company Ltd.', 'EQ', 'CONSUMER GOODS', 'INE280A01028'), ('ULTRACEMCO', 'UltraTech Cement Ltd.', 'EQ', 'CEMENT & CEMENT PRODUCTS', 'INE481G01011'), ('UPL', 'UPL Ltd.', 'EQ', 'FERTILISERS & PESTICIDES', 'INE628A01036'), ('VEDL', 'Vedanta Ltd.', 'EQ', 'METALS', 'INE205A01025'), ('WIPRO', 'Wipro Ltd.', 'EQ', 'IT', 'INE075A01022'), ('ZEEL', 'Zee Entertainment Enterprises Ltd.', 'EQ', 'MEDIA & ENTERTAINMENT', 'INE256A01028')]\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.sql.expression import select, text\n",
    "\n",
    "engine = create_engine('trino://trino@192.168.59.1:8085/iceberg')\n",
    "connection = engine.connect()\n",
    "\n",
    "rows = connection.execute(text(\"SELECT * FROM db.a\")).fetchall()\n",
    "print(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f35bf76f-ed23-44f6-aa8f-d88662aa1ded",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.engine.cursor.LegacyCursorResult at 0x7fa5fc802eb0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "connection.execute(text(\"CREATE SCHEMA IF NOT EXISTS iceberg.db with (location = 's3a://lakehouse/')\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "17caf4b5-6aa3-47b5-9413-b6c47153e4e1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ProgrammingError",
     "evalue": "(trino.exceptions.TrinoUserError) TrinoUserError(type=USER_ERROR, name=SYNTAX_ERROR, message=\"line 1:132: mismatched input 'USING'. Expecting: 'COMMENT', 'WITH', <EOF>\", query_id=20231102_175215_00163_gh2b3)\n[SQL: CREATE TABLE IF NOT EXISTS iceberg.db.b (Symbol varchar, CompanyName varchar, Series varchar, Industry varchar, ISIN_Code varchar) USING iceberg]\n(Background on this error at: https://sqlalche.me/e/14/f405)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTrinoUserError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/sqlalchemy/engine/base.py:1900\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[1;32m   1899\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evt_handled:\n\u001b[0;32m-> 1900\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_execute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1901\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[1;32m   1902\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1904\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_events \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39m_has_events:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/trino/sqlalchemy/dialect.py:399\u001b[0m, in \u001b[0;36mTrinoDialect.do_execute\u001b[0;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdo_execute\u001b[39m(\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;28mself\u001b[39m, cursor: Cursor, statement: \u001b[38;5;28mstr\u001b[39m, parameters: Tuple[Any, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m], context: DefaultExecutionContext \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    398\u001b[0m ):\n\u001b[0;32m--> 399\u001b[0m     \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/trino/dbapi.py:592\u001b[0m, in \u001b[0;36mCursor.execute\u001b[0;34m(self, operation, params)\u001b[0m\n\u001b[1;32m    590\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_query \u001b[38;5;241m=\u001b[39m trino\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mTrinoQuery(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request, query\u001b[38;5;241m=\u001b[39moperation,\n\u001b[1;32m    591\u001b[0m                                           legacy_primitive_types\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_legacy_primitive_types)\n\u001b[0;32m--> 592\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_query\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    593\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/trino/client.py:810\u001b[0m, in \u001b[0;36mTrinoQuery.execute\u001b[0;34m(self, additional_http_headers)\u001b[0m\n\u001b[1;32m    809\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinished \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcancelled \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\u001b[38;5;241m.\u001b[39mrows) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 810\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\u001b[38;5;241m.\u001b[39mrows \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    811\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/trino/client.py:830\u001b[0m, in \u001b[0;36mTrinoQuery.fetch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m trino\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mTrinoConnectionError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfailed to fetch: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(e))\n\u001b[0;32m--> 830\u001b[0m status \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_state(status)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/trino/client.py:609\u001b[0m, in \u001b[0;36mTrinoRequest.process\u001b[0;34m(self, http_response)\u001b[0m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m response:\n\u001b[0;32m--> 609\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_error(response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m], response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m    611\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m constants\u001b[38;5;241m.\u001b[39mHEADER_CLEAR_SESSION \u001b[38;5;129;01min\u001b[39;00m http_response\u001b[38;5;241m.\u001b[39mheaders:\n",
      "\u001b[0;31mTrinoUserError\u001b[0m: TrinoUserError(type=USER_ERROR, name=SYNTAX_ERROR, message=\"line 1:132: mismatched input 'USING'. Expecting: 'COMMENT', 'WITH', <EOF>\", query_id=20231102_175215_00163_gh2b3)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mProgrammingError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [34], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCREATE TABLE IF NOT EXISTS iceberg.db.b (Symbol varchar, CompanyName varchar, Series varchar, Industry varchar, ISIN_Code varchar) USING iceberg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/sqlalchemy/engine/base.py:1380\u001b[0m, in \u001b[0;36mConnection.execute\u001b[0;34m(self, statement, *multiparams, **params)\u001b[0m\n\u001b[1;32m   1376\u001b[0m     util\u001b[38;5;241m.\u001b[39mraise_(\n\u001b[1;32m   1377\u001b[0m         exc\u001b[38;5;241m.\u001b[39mObjectNotExecutableError(statement), replace_context\u001b[38;5;241m=\u001b[39merr\n\u001b[1;32m   1378\u001b[0m     )\n\u001b[1;32m   1379\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1380\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultiparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_EMPTY_EXECUTION_OPTS\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/sqlalchemy/sql/elements.py:333\u001b[0m, in \u001b[0;36mClauseElement._execute_on_connection\u001b[0;34m(self, connection, multiparams, params, execution_options, _force)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_execute_on_connection\u001b[39m(\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28mself\u001b[39m, connection, multiparams, params, execution_options, _force\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    331\u001b[0m ):\n\u001b[1;32m    332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _force \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupports_execution:\n\u001b[0;32m--> 333\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_clauseelement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultiparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution_options\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    336\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    337\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mObjectNotExecutableError(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/sqlalchemy/engine/base.py:1572\u001b[0m, in \u001b[0;36mConnection._execute_clauseelement\u001b[0;34m(self, elem, multiparams, params, execution_options)\u001b[0m\n\u001b[1;32m   1560\u001b[0m compiled_cache \u001b[38;5;241m=\u001b[39m execution_options\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m   1561\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompiled_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39m_compiled_cache\n\u001b[1;32m   1562\u001b[0m )\n\u001b[1;32m   1564\u001b[0m compiled_sql, extracted_params, cache_hit \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_compile_w_cache(\n\u001b[1;32m   1565\u001b[0m     dialect\u001b[38;5;241m=\u001b[39mdialect,\n\u001b[1;32m   1566\u001b[0m     compiled_cache\u001b[38;5;241m=\u001b[39mcompiled_cache,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1570\u001b[0m     linting\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdialect\u001b[38;5;241m.\u001b[39mcompiler_linting \u001b[38;5;241m|\u001b[39m compiler\u001b[38;5;241m.\u001b[39mWARN_LINTING,\n\u001b[1;32m   1571\u001b[0m )\n\u001b[0;32m-> 1572\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_context\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1573\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1574\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecution_ctx_cls\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_compiled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1575\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompiled_sql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1576\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistilled_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1577\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1578\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompiled_sql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1579\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistilled_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1580\u001b[0m \u001b[43m    \u001b[49m\u001b[43melem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1581\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextracted_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1582\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_hit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_hit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1584\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_events:\n\u001b[1;32m   1585\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch\u001b[38;5;241m.\u001b[39mafter_execute(\n\u001b[1;32m   1586\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1587\u001b[0m         elem,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1591\u001b[0m         ret,\n\u001b[1;32m   1592\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/sqlalchemy/engine/base.py:1943\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[1;32m   1940\u001b[0m             branched\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m   1942\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 1943\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_dbapi_exception\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1944\u001b[0m \u001b[43m        \u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[1;32m   1945\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1947\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/sqlalchemy/engine/base.py:2124\u001b[0m, in \u001b[0;36mConnection._handle_dbapi_exception\u001b[0;34m(self, e, statement, parameters, cursor, context)\u001b[0m\n\u001b[1;32m   2122\u001b[0m     util\u001b[38;5;241m.\u001b[39mraise_(newraise, with_traceback\u001b[38;5;241m=\u001b[39mexc_info[\u001b[38;5;241m2\u001b[39m], from_\u001b[38;5;241m=\u001b[39me)\n\u001b[1;32m   2123\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m should_wrap:\n\u001b[0;32m-> 2124\u001b[0m     \u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2125\u001b[0m \u001b[43m        \u001b[49m\u001b[43msqlalchemy_exception\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwith_traceback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43me\u001b[49m\n\u001b[1;32m   2126\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2127\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2128\u001b[0m     util\u001b[38;5;241m.\u001b[39mraise_(exc_info[\u001b[38;5;241m1\u001b[39m], with_traceback\u001b[38;5;241m=\u001b[39mexc_info[\u001b[38;5;241m2\u001b[39m])\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/sqlalchemy/util/compat.py:208\u001b[0m, in \u001b[0;36mraise_\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    205\u001b[0m     exception\u001b[38;5;241m.\u001b[39m__cause__ \u001b[38;5;241m=\u001b[39m replace_context\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 208\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m     \u001b[38;5;66;03m# credit to\u001b[39;00m\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;66;03m# https://cosmicpercolator.com/2016/01/13/exception-leaks-in-python-2-and-3/\u001b[39;00m\n\u001b[1;32m    212\u001b[0m     \u001b[38;5;66;03m# as the __traceback__ object creates a cycle\u001b[39;00m\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m exception, replace_context, from_, with_traceback\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/sqlalchemy/engine/base.py:1900\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[1;32m   1898\u001b[0m                 \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1899\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evt_handled:\n\u001b[0;32m-> 1900\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_execute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1901\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[1;32m   1902\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1904\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_events \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39m_has_events:\n\u001b[1;32m   1905\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch\u001b[38;5;241m.\u001b[39mafter_cursor_execute(\n\u001b[1;32m   1906\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1907\u001b[0m         cursor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1911\u001b[0m         context\u001b[38;5;241m.\u001b[39mexecutemany,\n\u001b[1;32m   1912\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/trino/sqlalchemy/dialect.py:399\u001b[0m, in \u001b[0;36mTrinoDialect.do_execute\u001b[0;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdo_execute\u001b[39m(\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;28mself\u001b[39m, cursor: Cursor, statement: \u001b[38;5;28mstr\u001b[39m, parameters: Tuple[Any, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m], context: DefaultExecutionContext \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    398\u001b[0m ):\n\u001b[0;32m--> 399\u001b[0m     \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/trino/dbapi.py:592\u001b[0m, in \u001b[0;36mCursor.execute\u001b[0;34m(self, operation, params)\u001b[0m\n\u001b[1;32m    589\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    590\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_query \u001b[38;5;241m=\u001b[39m trino\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mTrinoQuery(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request, query\u001b[38;5;241m=\u001b[39moperation,\n\u001b[1;32m    591\u001b[0m                                           legacy_primitive_types\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_legacy_primitive_types)\n\u001b[0;32m--> 592\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_query\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    593\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/trino/client.py:810\u001b[0m, in \u001b[0;36mTrinoQuery.execute\u001b[0;34m(self, additional_http_headers)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;66;03m# Execute should block until at least one row is received or query is finished or cancelled\u001b[39;00m\n\u001b[1;32m    809\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinished \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcancelled \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\u001b[38;5;241m.\u001b[39mrows) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 810\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\u001b[38;5;241m.\u001b[39mrows \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    811\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/trino/client.py:830\u001b[0m, in \u001b[0;36mTrinoQuery.fetch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mRequestException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m trino\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mTrinoConnectionError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfailed to fetch: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(e))\n\u001b[0;32m--> 830\u001b[0m status \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_state(status)\n\u001b[1;32m    832\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(status)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/trino/client.py:609\u001b[0m, in \u001b[0;36mTrinoRequest.process\u001b[0;34m(self, http_response)\u001b[0m\n\u001b[1;32m    607\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHTTP \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, http_response\u001b[38;5;241m.\u001b[39mstatus_code, response)\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m response:\n\u001b[0;32m--> 609\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_error(response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m], response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m    611\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m constants\u001b[38;5;241m.\u001b[39mHEADER_CLEAR_SESSION \u001b[38;5;129;01min\u001b[39;00m http_response\u001b[38;5;241m.\u001b[39mheaders:\n\u001b[1;32m    612\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m prop \u001b[38;5;129;01min\u001b[39;00m get_header_values(\n\u001b[1;32m    613\u001b[0m         http_response\u001b[38;5;241m.\u001b[39mheaders, constants\u001b[38;5;241m.\u001b[39mHEADER_CLEAR_SESSION\n\u001b[1;32m    614\u001b[0m     ):\n",
      "\u001b[0;31mProgrammingError\u001b[0m: (trino.exceptions.TrinoUserError) TrinoUserError(type=USER_ERROR, name=SYNTAX_ERROR, message=\"line 1:132: mismatched input 'USING'. Expecting: 'COMMENT', 'WITH', <EOF>\", query_id=20231102_175215_00163_gh2b3)\n[SQL: CREATE TABLE IF NOT EXISTS iceberg.db.b (Symbol varchar, CompanyName varchar, Series varchar, Industry varchar, ISIN_Code varchar) USING iceberg]\n(Background on this error at: https://sqlalche.me/e/14/f405)"
     ]
    }
   ],
   "source": [
    "connection.execute(text(\"CREATE TABLE IF NOT EXISTS iceberg.db.b (Symbol varchar, CompanyName varchar, Series varchar, Industry varchar, ISIN_Code varchar)\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103f4162-825b-4f9b-87f2-fd5f2007594e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82702846",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"iceberg\").load(\"hive_prod.silver.cleaned_stocks\")\n",
    "# df = df.withColumnRenamed(\"VWAP\", \"Volume_Weight_Avg_Price\") \\\n",
    "#     .withColumn(\"Date\", date_format(\"Date\", \"dd-MM-yyyy\")) \\\n",
    "#     .drop('ID')\n",
    "df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc8b0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(df['Open'])\n",
    "df.describe().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b8ec1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca0a941-1e4a-4a16-8b1f-d34c2b0b7641",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(['Open', 'High', 'Low', 'Last', 'Close', 'Volume']).describe().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97475261-c865-437a-8909-5e5ff17f30cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupBy('Symbol').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551bfa9b-8d14-4eed-a40d-6a6811605675",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56470bd8-35cd-4500-8b93-e5dff05511bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdfc = df.filter(col('Symbol')=='HDFC')\n",
    "hdfc.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2acb3a-59d5-4312-822f-3b56b7de7f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6574c9c1-8432-49a1-bf56-e83cc8daeebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupBy('Symbol') \\\n",
    "    .agg(min('Date').alias('Start'),\n",
    "         max('Date').alias('End'),\n",
    "         \n",
    "         min('Open').alias('Min_Open'),\n",
    "         max('Open').alias('Max_Open'),\n",
    "         avg('Open').alias('Avg_Open'),\n",
    "         \n",
    "         min('High').alias('Min_High'),\n",
    "         max('High').alias('Max_High'),\n",
    "         avg('High').alias('Avg_High'),\n",
    "         \n",
    "         min('Low').alias('Min_Low'),\n",
    "         max('Low').alias('Max_Low'),\n",
    "         avg('Low').alias('Avg_Low'),\n",
    "         \n",
    "         min('Last').alias('Min_Last'),\n",
    "         max('Last').alias('Max_Last'),\n",
    "         avg('Last').alias('Avg_Last'),\n",
    "         \n",
    "         min('Close').alias('Min_Close'),\n",
    "         max('Close').alias('Max_Close'),\n",
    "         avg('Close').alias('Avg_Close'),\n",
    "         \n",
    "         sum('Volume').alias('Sum_Volume'),\n",
    "        ).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "762b2a0e-aa84-41c9-a7d8-f2de84f91de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+----------+----------+----------+---------+----------+-----------+-----------------------+--------+----------------+------+------------------+-------------------+\n",
      "|      Date|    Symbol|Prev_Close|Open_Price|High_Price|Low_Price|Last_Price|Close_Price|Volume_Weight_Avg_Price|  Volume|        Turnover|Trades|Deliverable_Volume|Percent_Deliverable|\n",
      "+----------+----------+----------+----------+----------+---------+----------+-----------+-----------------------+--------+----------------+------+------------------+-------------------+\n",
      "|27-11-2007|ADANIPORTS|     440.0|     770.0|    1050.0|    770.0|     959.0|      962.9|                 984.72|27294366|2690000000000000|     0|           9859619|               0.36|\n",
      "|28-11-2007|ADANIPORTS|     962.9|     984.0|     990.0|    874.0|     885.0|      893.9|                 941.38| 4581338| 431000000000000|     0|           1453278|               0.32|\n",
      "|29-11-2007|ADANIPORTS|     893.9|     909.0|    914.75|    841.0|     887.0|      884.2|                 888.09| 5124121| 455000000000000|     0|           1069678|               0.21|\n",
      "+----------+----------+----------+----------+----------+---------+----------+-----------+-----------------------+--------+----------------+------+------------------+-------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.format(\"iceberg\").load(\"hive_prod.silver.cleaned_trades\")\n",
    "# df = df.withColumnRenamed(\"VWAP\", \"Volume_Weight_Avg_Price\") \\\n",
    "#     .withColumn(\"Date\", date_format(\"Date\", \"dd-MM-yyyy\")) \\\n",
    "#     .drop('ID')\n",
    "df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8950f86e-1225-422a-a4fe-b2132012b34b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS hive_prod.gold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d352c854-2424-4b7c-9af6-cf184c49e64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.format(\"iceberg\").mode(\"overwrite\").saveAsTable(\"hive_prod.gold.gold1\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
